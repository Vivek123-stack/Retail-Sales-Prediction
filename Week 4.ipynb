{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hbj_p704vmaq"
   },
   "source": [
    "***Project Owner : Sujay Torvi , Email me at sujay.torvi@gmail.com\n",
    "Copyright Â© 2019***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrR7wpk7vmk7"
   },
   "source": [
    "# AI Capstone Project\n",
    "## Domain: Retail\n",
    "## Problem Statement\n",
    "\n",
    "***Demand Forecast is one of the key tasks in Supply Chain and Retail Domain in general. It is key in effective operation and optimization of retail supply chain. Effectively solving this problem requires knowledge about a wide range of tricks in Data Sciences and good understanding of ensemble techniques.***\n",
    "***You are required to predict sales for each Store-Day level for one month. All the features will be provided and actual sales that happened during that month will also be provided for model evaluation.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gi_7V5DCvmwm"
   },
   "source": [
    "## Agenda for Week 4\n",
    "### Implementing Artificial Neural Networks\n",
    "### 1. Use ANN (Artificial Neural Network) to predict Store Sales.\n",
    "#### a)    Fine-tune number of layers,\n",
    "#### b)    Number of Neurons in each layers .\n",
    "#### c)    Experiment in batch-size.\n",
    "#### d)    Experiment with number of epochs. Carefully observe the loss and accuracy? What are the observations?\n",
    "#### e)    Play with different  Learning Rate  variants of Gradient Descent like Adam, SGD, RMS-prop.\n",
    "#### f)    Which activation performs best for this use case and why?\n",
    "#### g)    Check how it performed in the dataset, calculate RMSE.\n",
    "### 2. Use Dropout for ANN and find the optimum number of clusters (clusters formed considering the features: sales and customer visits). Compare model performance with traditional ML based prediction models. \n",
    "### 3. Find the best setting of neural net that minimizes the loss and can predict the sales best. Use techniques like Grid search, cross-validation and Random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0F8t7FwwdlT"
   },
   "outputs": [],
   "source": [
    "#Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-AmpQxsVcbj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWnpUJ6ECkPR"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "2STkk8DHVgJQ",
    "outputId": "c20bccba-6869-4d59-987e-4c294ebcaa80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  ...  Open  Promo  StateHoliday SchoolHoliday\n",
       "0      1          2  2015-06-30   5735  ...     1      1             0             0\n",
       "1      2          2  2015-06-30   9863  ...     1      1             0             0\n",
       "2      3          2  2015-06-30  13261  ...     1      1             0             1\n",
       "3      4          2  2015-06-30  13106  ...     1      1             0             0\n",
       "4      5          2  2015-06-30   6635  ...     1      1             0             0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "hKITlXGQVmWq",
    "outputId": "709ea524-8bb2-4b06-f1f5-5774e1a4354d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  ...  Promo  StateHoliday  SchoolHoliday\n",
       "0      1          5  2015-07-31  ...      1             0              1\n",
       "1      2          5  2015-07-31  ...      1             0              1\n",
       "2      3          5  2015-07-31  ...      1             0              1\n",
       "3      4          5  2015-07-31  ...      1             0              1\n",
       "4      5          5  2015-07-31  ...      1             0              1\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_data_hidden.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7U89SUVV7Gn"
   },
   "outputs": [],
   "source": [
    "train = train[train.Open == 1]\n",
    "train = train[['Store','DayOfWeek','Sales','Customers','Open','Promo','StateHoliday','SchoolHoliday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTIiEIK8V7LE"
   },
   "outputs": [],
   "source": [
    "test = test[test.Open == 1]\n",
    "test = test[['Store','DayOfWeek','Sales','Customers','Open','Promo','StateHoliday','SchoolHoliday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9lVpBIyYWOj"
   },
   "outputs": [],
   "source": [
    "#map a - 1, b- 2 & c - 3 in the state holiday\n",
    "def cleanHoliday(x):\n",
    "  if(x == 0):\n",
    "    x = '0'\n",
    "  elif(x == 'a'):\n",
    "    x = 1\n",
    "  elif(x == 'b'):\n",
    "    x = 2\n",
    "  elif(x == 'c'):\n",
    "    x = 3\n",
    "  return x\n",
    "train.StateHoliday = train.StateHoliday.map(cleanHoliday)\n",
    "test.StateHoliday = test.StateHoliday.map(cleanHoliday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6MPUvQkV7D8"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5AtLROuWm8-"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(train[['DayOfWeek','Customers','Open','Promo','StateHoliday','SchoolHoliday']])\n",
    "X_test = np.asarray(test[['DayOfWeek','Customers','Open','Promo','StateHoliday','SchoolHoliday']])\n",
    "y_train = np.asarray(train.Sales)\n",
    "y_test = np.asarray(test.Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMY_5ULjWm6T"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRavO8fuWm39"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "y_train = sc.fit_transform(y_train)\n",
    "y_test = sc.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz-HmgZ0Wm0l"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxzV_IRlY8hO"
   },
   "outputs": [],
   "source": [
    "pca = PCA(.95) #will retain 95% variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oYT9CjuCY8kg",
    "outputId": "2793499f-d3d5-4268-fb5f-2d05dfad8f5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CKZ9xKZoY8eB",
    "outputId": "05fb79c9-fda6-4529-b4a4-9a207e56ce07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_ #shows how many features pca chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeMU4Z_JZTq8"
   },
   "outputs": [],
   "source": [
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5_hgB9y2bpI"
   },
   "outputs": [],
   "source": [
    "y_test = sc.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rw6ONiZDapA9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DN1dOUq4xTCb"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras API to train neural network on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cu8c4sD6xlue"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation,Dropout,Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BaUtvOwNxDrD"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amjEnA5wCox0"
   },
   "source": [
    "### Train 5 Different Model with Different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYUPvrFuPJ1u"
   },
   "outputs": [],
   "source": [
    "def build_model_1():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "  model.add(Dense(3, kernel_initializer='normal'))\n",
    "  model.add(Dense(3, kernel_initializer='normal'))\n",
    "  model.add(Dense(1, kernel_initializer='normal'))\n",
    "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtDihLfvbnhC"
   },
   "outputs": [],
   "source": [
    "model = build_model_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceKf1TVLhn8E"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, batch_size = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLecKYfozzNr"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf7ng1QhzzVv"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M-dW0ptF0Aw7",
    "outputId": "3951ac3c-3264-402c-af60-53306e17a837"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513.7465158283935"
      ]
     },
     "execution_count": 175,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SF84gyUke6U"
   },
   "outputs": [],
   "source": [
    "def build_model_2():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "  model.add(Dense(3, kernel_initializer='normal'))\n",
    "  model.add(Dense(3, kernel_initializer='normal'))\n",
    "  model.add(Dense(1, kernel_initializer='normal'))\n",
    "  model.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_ZJRXwcuPkG"
   },
   "outputs": [],
   "source": [
    "model = build_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0UrL0DIuWKX"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, batch_size = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GH3kEYR-uWQX"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVcFrYUix68M"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Pdg0Zwyvur3w",
    "outputId": "9ffde915-53ee-451d-b3a2-2642aa6a7dbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1517.4411870630245"
      ]
     },
     "execution_count": 221,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTtnYZGBxe88"
   },
   "outputs": [],
   "source": [
    "def build_model_3():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(5, input_dim=5, kernel_initializer='random_normal', activation='relu'))\n",
    "  model.add(Dense(3, kernel_initializer='random_normal'))\n",
    "  model.add(Dense(1, kernel_initializer='random_normal'))\n",
    "  model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7UANkATxjzZ"
   },
   "outputs": [],
   "source": [
    "model = build_model_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXC2DzZWA6p-"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 150, batch_size = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-iqN5ILA6yp"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rn4pGCTKCcBT"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FHczU1oyBP_a",
    "outputId": "e476c277-c91d-497d-c239-f7ddcb78feaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525.6699726566487"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM4ybywMBSXT"
   },
   "outputs": [],
   "source": [
    "def build_model_4():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(5, input_dim=5, kernel_initializer='random_uniform', activation='relu'))\n",
    "  model.add(Dense(3, kernel_initializer='random_uniform'))\n",
    "  model.add(Dense(1, kernel_initializer='random_uniform'))\n",
    "  model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "tSI0N_mvG0tO",
    "outputId": "caf030f1-4621-434e-ae72-e17a30ddc242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RbksETIG42K"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 200, batch_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6MWJnloG464"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2k4QC9oHMlD"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S_VFp6-GHOr9",
    "outputId": "557f9646-74d8-4083-9d2b-ade23a88619f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1532.4700943526816"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjLSMgZIHrW8"
   },
   "outputs": [],
   "source": [
    "def build_model_5():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(5, input_dim=5, kernel_initializer='random_uniform', activation='relu'))\n",
    "  model.add(Dense(4, kernel_initializer='random_uniform'))\n",
    "  model.add(Dense(1, kernel_initializer='random_uniform'))\n",
    "  model.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_j65B5UzIV2I"
   },
   "outputs": [],
   "source": [
    "model = build_model_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRu4q8-zHwec"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, batch_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTXLxI08I_OU"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97v-rKreI_Lf"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M-Cq1No6I_I1",
    "outputId": "d87f371e-ba77-4298-a1ec-6b593fef027e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514.9820586407577"
      ]
     },
     "execution_count": 250,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gt3OkeAcCxiq"
   },
   "source": [
    "### **Lets Draw A Comparision**\n",
    "\n",
    "### **Neural Networks**:\n",
    "\n",
    "|Model No.| Learning Variant | Activation Function | Batch Size | Epoch | Layers | RMSE\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| Model 1| Adam | Relu | 25000 | 100 | 4 | 1513.74\n",
    "| Model 2 | Adagrad | Relu | 2500 | 100| 4 | 1517.44\n",
    "| Model 3 | SGD | Relu | 2500 | 150| 3 | 1525.66\n",
    "| Model 4 | RMSProp | Relu | 5000 | 200| 4 | 1532.47\n",
    "| Model 4 | Adadelta | Relu | 10000 | 100| 4 | 1514.98\n",
    "\n",
    "### **Model 1 has the lowest RMSE Score**\n",
    "### ***Best Activation Function***\n",
    "### The best activation function for this usecase is Relu. You can also use linear activation function for a regression problem but it is not appropriate for this usecase as you dont want to handle negative customer visits. Sigmoid is not appropriate for this usecase as it is converting the values to a probability value, same goes for softmax activation(only difference is sigmoid is suited for binary classification & softmax is used for multiclass classification). \n",
    "\n",
    "### ***Batch Size*** \n",
    "### It depends, it should not be too high and not too low. If neural network is not too complex a lesser batch size can (and is recommended) be used, otherwise stick to larger batch sizes. Also SGD does not learn at all or learns very slowly at high batch sizes : in this usecase when SGD was used with 100,000  Batch size at about 20 epochs it stopped learning and the loss was constant. Seemed like a bad activation, but it is not , actually it works good at low batch sizes.\n",
    "\n",
    "### ***No. of Layers & No. of neuron in each layer***\n",
    "### For structured data neural networks do not need to be very complex and hidden layers can be of 1 or 2 layers(total 3 or 4 including input & output layers). No. of hidden neurons can be the mean of neurons in input and output layer.\n",
    "\n",
    "### ***Epochs***\n",
    "### The number of epochs should not be too high nor too low. In this usecase 100 epochs are sufficient. As it can be seen when 150, or 200 epochs were used it started to overfit. However for SGD epochs needed were slightly high as it was learning slowly as compared to adam or adagrad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zTSMceIK9rt"
   },
   "outputs": [],
   "source": [
    "# use sales and customer visits & include dropout neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "yVndvzVEHNMs",
    "outputId": "2f7cb52b-5992-40c1-bd50-5430be2958ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data_hidden.csv')\n",
    "train = train[train.Open == 1]\n",
    "test = test[test.Open == 1]\n",
    "train = train[['Sales','Customers']]\n",
    "test = test[['Sales','Customers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5We7BdlLGK6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZ72vh6fXtBQ"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(train.Customers)\n",
    "X_test = np.asarray(test.Customers)\n",
    "y_train = np.asarray(train.Sales)\n",
    "y_test = np.asarray(test.Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jqsnQEGYI2T"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAHI3Oc1LOW2"
   },
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "y_train = sc.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oXTj9w0LT3y"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5zDAtmrSooN"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(1, input_dim=1, kernel_initializer='normal', activation='relu'))\n",
    "  model.add(Dense(4, kernel_initializer='normal'))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Dense(4, kernel_initializer='normal'))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Dense(1, kernel_initializer='normal'))\n",
    "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_3jkPISIWtJH"
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vjGpkKxqWtpl",
    "outputId": "fc2e1e78-9d9a-448a-fa47-31a89abe51cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "814204/814204 [==============================] - 1s 2us/step - loss: 1.0000\n",
      "Epoch 2/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 1.0000\n",
      "Epoch 3/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 1.0000\n",
      "Epoch 4/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 1.0000\n",
      "Epoch 5/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9999\n",
      "Epoch 6/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9997\n",
      "Epoch 7/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9994\n",
      "Epoch 8/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9988\n",
      "Epoch 9/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9977\n",
      "Epoch 10/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9959\n",
      "Epoch 11/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9931\n",
      "Epoch 12/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9888\n",
      "Epoch 13/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9826\n",
      "Epoch 14/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9740\n",
      "Epoch 15/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9624\n",
      "Epoch 16/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9473\n",
      "Epoch 17/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9280\n",
      "Epoch 18/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9044\n",
      "Epoch 19/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8756\n",
      "Epoch 20/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8424\n",
      "Epoch 21/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8040\n",
      "Epoch 22/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.7621\n",
      "Epoch 23/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.7170\n",
      "Epoch 24/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.6724\n",
      "Epoch 25/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.6275\n",
      "Epoch 26/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5869\n",
      "Epoch 27/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5521\n",
      "Epoch 28/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5251\n",
      "Epoch 29/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5053\n",
      "Epoch 30/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4934\n",
      "Epoch 31/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4865\n",
      "Epoch 32/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4812\n",
      "Epoch 33/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4789\n",
      "Epoch 34/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4762\n",
      "Epoch 35/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4742\n",
      "Epoch 36/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4712\n",
      "Epoch 37/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4676\n",
      "Epoch 38/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4645\n",
      "Epoch 39/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4618\n",
      "Epoch 40/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4601\n",
      "Epoch 41/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4575\n",
      "Epoch 42/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4537\n",
      "Epoch 43/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4520\n",
      "Epoch 44/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4495\n",
      "Epoch 45/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4478\n",
      "Epoch 46/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4450\n",
      "Epoch 47/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4436\n",
      "Epoch 48/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4411\n",
      "Epoch 49/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4384\n",
      "Epoch 50/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4357\n",
      "Epoch 51/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4362\n",
      "Epoch 52/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4324\n",
      "Epoch 53/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4314\n",
      "Epoch 54/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4309\n",
      "Epoch 55/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4283\n",
      "Epoch 56/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4267\n",
      "Epoch 57/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4250\n",
      "Epoch 58/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4236\n",
      "Epoch 59/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4211\n",
      "Epoch 60/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4202\n",
      "Epoch 61/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4195\n",
      "Epoch 62/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4174\n",
      "Epoch 63/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4175\n",
      "Epoch 64/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4147\n",
      "Epoch 65/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4148\n",
      "Epoch 66/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4133\n",
      "Epoch 67/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4120\n",
      "Epoch 68/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4118\n",
      "Epoch 69/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4108\n",
      "Epoch 70/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4103\n",
      "Epoch 71/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4090\n",
      "Epoch 72/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4088\n",
      "Epoch 73/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4079\n",
      "Epoch 74/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4079\n",
      "Epoch 75/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4065\n",
      "Epoch 76/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4077\n",
      "Epoch 77/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4071\n",
      "Epoch 78/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4071\n",
      "Epoch 79/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4061\n",
      "Epoch 80/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4053\n",
      "Epoch 81/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4045\n",
      "Epoch 82/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4043\n",
      "Epoch 83/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4055\n",
      "Epoch 84/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4030\n",
      "Epoch 85/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4039\n",
      "Epoch 86/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4043\n",
      "Epoch 87/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4035\n",
      "Epoch 88/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4032\n",
      "Epoch 89/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4044\n",
      "Epoch 90/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4041\n",
      "Epoch 91/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4036\n",
      "Epoch 92/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4056\n",
      "Epoch 93/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4030\n",
      "Epoch 94/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4044\n",
      "Epoch 95/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4022\n",
      "Epoch 96/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4035\n",
      "Epoch 97/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4031\n",
      "Epoch 98/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4036\n",
      "Epoch 99/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4044\n",
      "Epoch 100/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4017\n",
      "Epoch 101/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4036\n",
      "Epoch 102/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4020\n",
      "Epoch 103/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4041\n",
      "Epoch 104/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4029\n",
      "Epoch 105/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4033\n",
      "Epoch 106/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4035\n",
      "Epoch 107/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4026\n",
      "Epoch 108/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4037\n",
      "Epoch 109/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4028\n",
      "Epoch 110/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4041\n",
      "Epoch 111/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4033\n",
      "Epoch 112/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4029\n",
      "Epoch 113/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4034\n",
      "Epoch 114/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4029\n",
      "Epoch 115/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4045\n",
      "Epoch 116/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4032\n",
      "Epoch 117/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4027\n",
      "Epoch 118/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4032\n",
      "Epoch 119/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4034\n",
      "Epoch 120/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4020\n",
      "Epoch 121/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4028\n",
      "Epoch 122/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4029\n",
      "Epoch 123/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4042\n",
      "Epoch 124/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4018\n",
      "Epoch 125/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4037\n",
      "Epoch 126/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4029\n",
      "Epoch 127/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4038\n",
      "Epoch 128/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4041\n",
      "Epoch 129/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4037\n",
      "Epoch 130/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4031\n",
      "Epoch 131/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4031\n",
      "Epoch 132/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4036\n",
      "Epoch 133/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4015\n",
      "Epoch 134/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4033\n",
      "Epoch 135/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4027\n",
      "Epoch 136/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4014\n",
      "Epoch 137/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4029\n",
      "Epoch 138/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4034\n",
      "Epoch 139/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4042\n",
      "Epoch 140/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4031\n",
      "Epoch 141/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4032\n",
      "Epoch 142/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4032\n",
      "Epoch 143/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4032\n",
      "Epoch 144/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4026\n",
      "Epoch 145/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4032\n",
      "Epoch 146/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4020\n",
      "Epoch 147/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4025\n",
      "Epoch 148/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4037\n",
      "Epoch 149/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4037\n",
      "Epoch 150/150\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd13e0fd780>"
      ]
     },
     "execution_count": 182,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 150, batch_size = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-a5joA06Wtvk"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tV9rjGUfXY5u"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ttnH-0gTXg5c",
    "outputId": "85229978-a3ff-4012-9f37-40b93296e4bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1722.1393804697086"
      ]
     },
     "execution_count": 189,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPv73f1UNdV6"
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nA_zTthNdfx"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "jQx0urvSO4he",
    "outputId": "ae7503c4-d9ec-40e0-9920-0c9b9127ee0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]\n",
      "Epoch [2]\n",
      "Epoch [3]\n",
      "Epoch [4]\n",
      "Epoch [5]\n",
      "Epoch [6]\n",
      "Epoch [7]\n",
      "Epoch [8]\n",
      "Epoch [9]\n",
      "Epoch [10]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(y_pred)\n",
    "    print('Epoch [{}]'.format(i))\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "mG7kJzp3PA0x",
    "outputId": "0e3df6f2-75f0-4d40-c5bb-26ee22f266c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]\n",
      "Epoch [2]\n",
      "Epoch [3]\n",
      "Epoch [4]\n",
      "Epoch [5]\n",
      "Epoch [6]\n",
      "Epoch [7]\n",
      "Epoch [8]\n",
      "Epoch [9]\n",
      "Epoch [10]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAFNCAYAAABPFDGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(y_train)\n",
    "    print('Epoch [{}]'.format(i))\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3yE2HTuQu7g"
   },
   "source": [
    "## Optimal number of clusters is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qeWfsUYhQ04G"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUyggXIJRGOr"
   },
   "outputs": [],
   "source": [
    "linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hI9XEtCJRGdh",
    "outputId": "3b9cc16e-d76b-4d1a-c425-9f30291af5f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qq_bw-QARGbE"
   },
   "outputs": [],
   "source": [
    "y_new_pred = linear.predict(X_test)\n",
    "y_new_pred1 = linear.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sJRa27ZzRqVM",
    "outputId": "e44a48e9-426a-4795-b6e4-fdc304176f0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5655610752118618"
      ]
     },
     "execution_count": 202,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_new_pred1,y_train))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dSc0RKtFRGXu",
    "outputId": "899168c7-23e6-431b-ef49-137922bbfe9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7621.747033216892"
      ]
     },
     "execution_count": 199,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_new_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwkuO-kiRh3x"
   },
   "source": [
    "### As we can see the Linear Regression Model has highly overfitted [we can observe from the RMSE], hence neural network with dropout performs highly better than the linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqC_YQ3DejVa"
   },
   "source": [
    "### Best setting of neural net - use Hyperparameter Tuning(GridsearchCV , Randomized Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iWBkhTxi3St"
   },
   "outputs": [],
   "source": [
    "def create_model(activation,optimizer,neurons):\n",
    "    # default values\n",
    "    activation='relu' \n",
    "    dropout_rate=0.4\n",
    "    init_mode='uniform' \n",
    "    optimizer='adam' \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(dropout_rate)) \n",
    "    model.add(Dense(neurons, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRGefZUetyFR"
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, batch_size=1000, epochs=10,verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeNpKTJzt8iY"
   },
   "outputs": [],
   "source": [
    "#Parameter Space\n",
    "neurons = [3, 5]\n",
    "activation =  ['relu']\n",
    "optimizer = ['RMSprop', 'Adagrad', 'Adam']\n",
    "# grid search epochs, batch size\n",
    "epochs = [100] \n",
    "batch_size = [1000,2500,5000,50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXWA_AZVv-P4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsfhT4B7uu0a"
   },
   "outputs": [],
   "source": [
    "param_grid = dict(epochs=epochs, batch_size=batch_size,activation = activation, optimizer = optimizer,neurons = neurons)\n",
    "grid = GridSearchCV(estimator=model, cv = 3, param_grid=param_grid, n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Kc5r9XpoyBTV",
    "outputId": "f9187fde-767e-4e19-9046-207cf6ff01f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "814204/814204 [==============================] - 2s 3us/step - loss: 0.7969\n",
      "Epoch 2/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.4898\n",
      "Epoch 3/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.4170\n",
      "Epoch 4/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.3716\n",
      "Epoch 5/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.3395\n",
      "Epoch 6/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.3176\n",
      "Epoch 7/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.3017\n",
      "Epoch 8/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2896\n",
      "Epoch 9/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2800\n",
      "Epoch 10/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2725\n",
      "Epoch 11/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2664\n",
      "Epoch 12/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2616\n",
      "Epoch 13/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2575\n",
      "Epoch 14/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2540\n",
      "Epoch 15/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2509\n",
      "Epoch 16/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2482\n",
      "Epoch 17/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2462\n",
      "Epoch 18/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2446\n",
      "Epoch 19/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2434\n",
      "Epoch 20/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2424\n",
      "Epoch 21/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2417\n",
      "Epoch 22/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2410\n",
      "Epoch 23/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2405\n",
      "Epoch 24/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2401\n",
      "Epoch 25/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2398\n",
      "Epoch 26/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2394\n",
      "Epoch 27/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2393\n",
      "Epoch 28/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2390\n",
      "Epoch 29/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2389\n",
      "Epoch 30/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2387\n",
      "Epoch 31/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2386\n",
      "Epoch 32/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2385\n",
      "Epoch 33/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2383\n",
      "Epoch 34/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2383\n",
      "Epoch 35/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2383\n",
      "Epoch 36/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2381\n",
      "Epoch 37/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2381\n",
      "Epoch 38/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2381\n",
      "Epoch 39/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2380\n",
      "Epoch 40/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2380\n",
      "Epoch 41/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2380\n",
      "Epoch 42/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2379\n",
      "Epoch 43/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2379\n",
      "Epoch 44/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2379\n",
      "Epoch 45/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2378\n",
      "Epoch 46/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2378\n",
      "Epoch 47/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2379\n",
      "Epoch 48/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2378\n",
      "Epoch 49/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2378\n",
      "Epoch 50/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2378\n",
      "Epoch 51/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2378\n",
      "Epoch 52/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2377\n",
      "Epoch 53/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2377\n",
      "Epoch 54/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2377\n",
      "Epoch 55/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2377\n",
      "Epoch 56/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2377\n",
      "Epoch 57/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2376\n",
      "Epoch 58/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2376\n",
      "Epoch 59/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2375\n",
      "Epoch 60/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2375\n",
      "Epoch 61/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2375\n",
      "Epoch 62/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2374\n",
      "Epoch 63/100\n",
      "814204/814204 [==============================] - 1s 2us/step - loss: 0.2372\n",
      "Epoch 64/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2372\n",
      "Epoch 65/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2371\n",
      "Epoch 66/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2369\n",
      "Epoch 67/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2368\n",
      "Epoch 68/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2367\n",
      "Epoch 69/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2365\n",
      "Epoch 70/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2364\n",
      "Epoch 71/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2362\n",
      "Epoch 72/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2360\n",
      "Epoch 73/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2359\n",
      "Epoch 74/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2358\n",
      "Epoch 75/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2358\n",
      "Epoch 76/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2357\n",
      "Epoch 77/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2357\n",
      "Epoch 78/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2356\n",
      "Epoch 79/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2356\n",
      "Epoch 80/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2356\n",
      "Epoch 81/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2356\n",
      "Epoch 82/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2355\n",
      "Epoch 83/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2355\n",
      "Epoch 84/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2355\n",
      "Epoch 85/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2354\n",
      "Epoch 86/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2354\n",
      "Epoch 87/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2353\n",
      "Epoch 88/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2353\n",
      "Epoch 89/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2353\n",
      "Epoch 90/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2353\n",
      "Epoch 91/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2353\n",
      "Epoch 92/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2352\n",
      "Epoch 93/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2352\n",
      "Epoch 94/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2351\n",
      "Epoch 95/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2351\n",
      "Epoch 96/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2351\n",
      "Epoch 97/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2350\n",
      "Epoch 98/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2350\n",
      "Epoch 99/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2350\n",
      "Epoch 100/100\n",
      "814204/814204 [==============================] - 2s 2us/step - loss: 0.2350\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "  grid_search = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pvjMyXabzEEp",
    "outputId": "f4edefe8-76a5-4443-978a-a80940c02fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30188/30188 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76s2zuqw1av4"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3dgkyaO7AfTb",
    "outputId": "360578d4-5326-4fad-c730-806dbe2cec17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515.1032325403005"
      ]
     },
     "execution_count": 153,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "XvzSVkfvE8qM",
    "outputId": "35aa1ba5-80bd-47bf-f7b3-9889f4868825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 2500,\n",
       " 'epochs': 100,\n",
       " 'neurons': 3,\n",
       " 'optimizer': 'Adagrad'}"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uVTXpAZ9UOF"
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, batch_size=1000, epochs=10,verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7E1iqZ2GFu7"
   },
   "outputs": [],
   "source": [
    "param_grid = dict(epochs=epochs, batch_size=batch_size, activation = activation, optimizer = optimizer, neurons = neurons)\n",
    "random_cv = RandomizedSearchCV(estimator = model, param_distributions = param_grid, n_iter = 4, cv = 2, verbose=1, random_state=11, n_jobs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bo8qXYgu_uQM",
    "outputId": "f0ce03b1-b33f-4be9-caef-70e01b21e192"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 1 is smaller than n_iter=4. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   2 | elapsed:   35.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   2 | elapsed:   35.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "814204/814204 [==============================] - 1s 1us/step - loss: 1.0000 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 1.0000 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 1.0000 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 1.0000 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 1.0000 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9999 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9999 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9999 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9998 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9997 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9995 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9993 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9990 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9987 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9982 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9975 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9966 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9955 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9942 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9924 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9903 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9877 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9845 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9807 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9763 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9711 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9650 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9581 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9502 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9413 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9313 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9202 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.9079 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8945 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8798 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8639 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8468 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8285 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.8090 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.7884 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.7667 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.7441 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.7206 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.6963 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.6715 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.6464 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.6211 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5959 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5710 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5468 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5235 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.5013 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4805 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4613 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4438 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4282 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4144 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.4025 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3922 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3834 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3761 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3700 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3648 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3603 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3565 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3531 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3501 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3473 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3446 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3422 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3398 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3375 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3354 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3333 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3312 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3292 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3273 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3255 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3237 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3219 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3203 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3186 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3170 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3155 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3140 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3126 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3112 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3098 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3085 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3072 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3059 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3047 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3035 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3023 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3011 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.3000 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.2989 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.2979 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.2969 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "814204/814204 [==============================] - 0s 0us/step - loss: 0.2959 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "  random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "1yrVjHvIGtC2",
    "outputId": "61e019ec-9e50-4919-a15a-5eca6b84e169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 5000,\n",
       " 'epochs': 100,\n",
       " 'neurons': 5,\n",
       " 'optimizer': 'Adagrad'}"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nLA5_E3yH2eB",
    "outputId": "bc745c60-2916-4804-8def-0493aee5f9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30188/30188 [==============================] - 0s 3us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = random_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvij67eaKvtH"
   },
   "outputs": [],
   "source": [
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UDRAErgJJpYz",
    "outputId": "a1cc2bd8-c95c-4516-9f8f-d8a01b18b846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1622.2525457850575"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred,y_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmMx1YhML8Ck"
   },
   "source": [
    "### Here Grid Search and Randomized Search have been used. Parameter Space has been kept simple so that it does not take too long to train. When parameter space is large it takes hours to search for best parameters even on an average GPU. \n",
    "\n",
    "### Although Grid Search takes longer than Random Search , it performs better than the Random Search. Better Results can be achieved if parameter space is increased further. \n",
    "\n",
    "### Cross validation is built into Grid Search and Random Search and it can be set in the respective search's hyperparameters\n",
    "\n",
    "### **Grid Search : RMSE - 1515.1032**\n",
    "### **Best Parameters:**\n",
    "#### {'activation': 'relu',\n",
    "#### 'batch_size': 2500,\n",
    "#### 'epochs': 100,\n",
    "#### 'neurons': 3,\n",
    "#### 'optimizer': 'Adagrad'}\n",
    "\n",
    "### **Randomized Search : RMSE - 1622.25\n",
    "### **Best Parameters:**\n",
    "#### {'activation': 'relu',\n",
    "#### 'batch_size': 5000,\n",
    "#### 'epochs': 100,\n",
    "#### 'neurons': 5,\n",
    "#### 'optimizer': 'Adagrad'}\n",
    "\n",
    "### As Random Search had a less parameter space and had less chances to randomly choose from the parameters than grid search , hence it performed poorly. \n",
    "\n",
    "### Bayesian Search is a good alternative technique to above hyperparameter tuning techniques , it conserves computational cost & time as well as gives good search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVLUHzWZbaVR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
